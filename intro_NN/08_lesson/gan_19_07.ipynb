{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCdGFvtyItIK"
   },
   "source": [
    "# GAN  `Model.train_step`\n",
    "\n",
    "(https://twitter.com/fchollet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZn7_uCAItIM"
   },
   "source": [
    "## Загрузка модулей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QPbdfnz4ItIO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eL0jLVLItIV"
   },
   "source": [
    "## строим Fashion_MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r_5cxeh_ItIW",
    "outputId": "f1f5fe10-2d8f-4dde-80c5-c419d5decca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# fashion MNIST \n",
    "class_ = 0\n",
    "batch_size = 64\n",
    "(x_train, y), (x_test, yt) = keras.datasets.fashion_mnist.load_data()\n",
    "all_digits = np.concatenate([x_train, x_test])\n",
    "all_digits = all_digits.astype(\"float32\") / 255\n",
    "ind_i = np.where(y == class_)\n",
    "ind_it = np.where(yt == class_)\n",
    "all_digits = all_digits[ind_i,:,:]\n",
    "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
    "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9GINZz5ItIb"
   },
   "source": [
    "## Строим discriminator\n",
    "\n",
    "размер карты 28x28 и бинарная классификация (настоящее изображение или генерировано)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K99eZdkgItIc",
    "outputId": "8a67768a-f36e-4d48-ffb1-ae0348e4e874"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 74,625\n",
      "Trainable params: 74,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eodbCQ1WItIh"
   },
   "source": [
    "## Строим generator\n",
    "\n",
    "обратное по отношению к дискриминатору преобразование, меняем `Conv2D` на `Conv2DTranspose` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PY5lCMxqItIi",
    "outputId": "282e502b-6e15-4bde-b243-bb64d90f9ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 6272)              809088    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 1)         12545     \n",
      "=================================================================\n",
      "Total params: 1,608,449\n",
      "Trainable params: 1,608,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        # строим размер входного вектора 7x7x128 map\n",
    "        layers.Dense(7 * 7 * 128),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((7, 7, 128)),\n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpX7dJvAItIn"
   },
   "source": [
    "## Класс со своим этапом обучения `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oHP6aHUfItIo"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "        # берем случайный пример из скрытого пространства\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Строим по нему фейковое изображение\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # собрали с реальным в текзор\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # задаем метки 1 и 0 соответственно\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Добавляем шум !!!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # учим discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        #Выбрали случайный пример в скрытом пространстве\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # собрали метки реальных изображений\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Учим generator !\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4rYDb3qItIs"
   },
   "source": [
    "## Callback для сохранения изображений по ходу обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QoLCvAe7ItIt"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"generated_img_{i}_{epoch}.png\".format(i=i, epoch=epoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiMWOk1_ItIz"
   },
   "source": [
    "## Учим end-to-end модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZSj0hUHItI0",
    "outputId": "9e9ecc6a-4b1d-4e59-8b2a-344e2c9caa1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "94/94 [==============================] - 5s 45ms/step - d_loss: 0.0805 - g_loss: 3.9338\n",
      "Epoch 2/150\n",
      "94/94 [==============================] - 4s 45ms/step - d_loss: 0.0751 - g_loss: 4.1455\n",
      "Epoch 3/150\n",
      "94/94 [==============================] - 4s 45ms/step - d_loss: 0.0696 - g_loss: 4.1855\n",
      "Epoch 4/150\n",
      "94/94 [==============================] - 4s 45ms/step - d_loss: 0.0612 - g_loss: 4.3475\n",
      "Epoch 5/150\n",
      "94/94 [==============================] - 4s 45ms/step - d_loss: 0.0515 - g_loss: 4.6095\n",
      "Epoch 6/150\n",
      "94/94 [==============================] - 4s 45ms/step - d_loss: 0.0456 - g_loss: 4.7997\n",
      "Epoch 7/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.0528 - g_loss: 4.5778\n",
      "Epoch 8/150\n",
      "94/94 [==============================] - 4s 45ms/step - d_loss: 0.0471 - g_loss: 4.6299\n",
      "Epoch 9/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.0321 - g_loss: 6.3005\n",
      "Epoch 10/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: -0.0026 - g_loss: 8.9860\n",
      "Epoch 11/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.0233 - g_loss: 6.7329\n",
      "Epoch 12/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.0321 - g_loss: 5.7743\n",
      "Epoch 13/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.0816 - g_loss: 4.2512\n",
      "Epoch 14/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.5146 - g_loss: 2.2224\n",
      "Epoch 15/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 1.0223 - g_loss: 0.9118\n",
      "Epoch 16/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.8824 - g_loss: 0.9329\n",
      "Epoch 17/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.8387 - g_loss: 1.0588\n",
      "Epoch 18/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.7650 - g_loss: 1.0735\n",
      "Epoch 19/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.9298 - g_loss: 0.7015\n",
      "Epoch 20/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.8019 - g_loss: 0.7728\n",
      "Epoch 21/150\n",
      "94/94 [==============================] - 4s 46ms/step - d_loss: 0.6847 - g_loss: 1.1989\n",
      "Epoch 22/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.3136 - g_loss: 1.8969\n",
      "Epoch 23/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6296 - g_loss: 1.2688\n",
      "Epoch 24/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7584 - g_loss: 0.9438\n",
      "Epoch 25/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7398 - g_loss: 0.9218\n",
      "Epoch 26/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.8421 - g_loss: 0.7307\n",
      "Epoch 27/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7600 - g_loss: 0.8373\n",
      "Epoch 28/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7107 - g_loss: 1.0050\n",
      "Epoch 29/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7356 - g_loss: 1.0107\n",
      "Epoch 30/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.8387 - g_loss: 0.8307\n",
      "Epoch 31/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7420 - g_loss: 0.8123\n",
      "Epoch 32/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7008 - g_loss: 0.9182\n",
      "Epoch 33/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7287 - g_loss: 0.8595\n",
      "Epoch 34/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7189 - g_loss: 0.8280\n",
      "Epoch 35/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7140 - g_loss: 0.8441\n",
      "Epoch 36/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6440 - g_loss: 0.9979\n",
      "Epoch 37/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6324 - g_loss: 0.9971\n",
      "Epoch 38/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7193 - g_loss: 0.8638\n",
      "Epoch 39/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7496 - g_loss: 0.9359\n",
      "Epoch 40/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5666 - g_loss: 1.2969\n",
      "Epoch 41/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7180 - g_loss: 0.9446\n",
      "Epoch 42/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7442 - g_loss: 0.8023\n",
      "Epoch 43/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7399 - g_loss: 0.8129\n",
      "Epoch 44/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7296 - g_loss: 0.7996\n",
      "Epoch 45/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6766 - g_loss: 0.9251\n",
      "Epoch 46/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6860 - g_loss: 0.9904\n",
      "Epoch 47/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.8558 - g_loss: 0.7473\n",
      "Epoch 48/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7466 - g_loss: 0.8289\n",
      "Epoch 49/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.7110 - g_loss: 0.8359\n",
      "Epoch 50/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5913 - g_loss: 0.9687\n",
      "Epoch 51/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6647 - g_loss: 0.9408\n",
      "Epoch 52/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.7533 - g_loss: 0.8972\n",
      "Epoch 53/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7528 - g_loss: 0.7661\n",
      "Epoch 54/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6057 - g_loss: 0.9194\n",
      "Epoch 55/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6071 - g_loss: 0.9819\n",
      "Epoch 56/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6337 - g_loss: 0.9129\n",
      "Epoch 57/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5290 - g_loss: 1.0850\n",
      "Epoch 58/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.4103 - g_loss: 1.3599\n",
      "Epoch 59/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.6911 - g_loss: 0.9656\n",
      "Epoch 60/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6367 - g_loss: 0.9509\n",
      "Epoch 61/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.6365 - g_loss: 0.9246\n",
      "Epoch 62/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6662 - g_loss: 0.9092\n",
      "Epoch 63/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5932 - g_loss: 0.9982\n",
      "Epoch 64/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6360 - g_loss: 0.8982\n",
      "Epoch 65/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5618 - g_loss: 1.0322\n",
      "Epoch 66/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5190 - g_loss: 1.1546\n",
      "Epoch 67/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6400 - g_loss: 0.9782\n",
      "Epoch 68/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6235 - g_loss: 0.9689\n",
      "Epoch 69/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.7257 - g_loss: 0.9296\n",
      "Epoch 70/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6739 - g_loss: 0.9733\n",
      "Epoch 71/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.5860 - g_loss: 1.0696\n",
      "Epoch 72/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5974 - g_loss: 0.9944\n",
      "Epoch 73/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.6471 - g_loss: 0.9983\n",
      "Epoch 74/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.7761 - g_loss: 0.7534\n",
      "Epoch 75/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.7294 - g_loss: 0.7854\n",
      "Epoch 76/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.7101 - g_loss: 0.8038\n",
      "Epoch 77/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6772 - g_loss: 0.8464\n",
      "Epoch 78/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6217 - g_loss: 0.9785\n",
      "Epoch 79/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.4146 - g_loss: 1.3308\n",
      "Epoch 80/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6007 - g_loss: 1.1126\n",
      "Epoch 81/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5496 - g_loss: 1.1661\n",
      "Epoch 82/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5583 - g_loss: 1.0987\n",
      "Epoch 83/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5414 - g_loss: 1.1520\n",
      "Epoch 84/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5678 - g_loss: 1.1381\n",
      "Epoch 85/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.8097 - g_loss: 0.8165\n",
      "Epoch 86/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.7849 - g_loss: 0.8310\n",
      "Epoch 87/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.7317 - g_loss: 0.8475\n",
      "Epoch 88/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6756 - g_loss: 0.9092\n",
      "Epoch 89/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.7093 - g_loss: 0.8755\n",
      "Epoch 90/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6815 - g_loss: 1.0147\n",
      "Epoch 91/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.4660 - g_loss: 2.0488\n",
      "Epoch 92/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.1599 - g_loss: 3.4669\n",
      "Epoch 93/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.0268 - g_loss: 4.6367\n",
      "Epoch 94/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.2535 - g_loss: 2.1314\n",
      "Epoch 95/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.4749 - g_loss: 1.5325\n",
      "Epoch 96/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5979 - g_loss: 1.0634\n",
      "Epoch 97/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6225 - g_loss: 1.0145\n",
      "Epoch 98/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.4721 - g_loss: 1.2554\n",
      "Epoch 99/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.4028 - g_loss: 1.4261\n",
      "Epoch 100/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6382 - g_loss: 1.2349\n",
      "Epoch 101/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.7340 - g_loss: 1.0372\n",
      "Epoch 102/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.7839 - g_loss: 0.9386\n",
      "Epoch 103/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.8006 - g_loss: 0.7634\n",
      "Epoch 104/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6176 - g_loss: 1.0004\n",
      "Epoch 105/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5764 - g_loss: 1.0321\n",
      "Epoch 106/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.5467 - g_loss: 1.1534\n",
      "Epoch 107/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6277 - g_loss: 1.2742\n",
      "Epoch 108/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.7955 - g_loss: 0.8385\n",
      "Epoch 109/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.7868 - g_loss: 0.7918\n",
      "Epoch 110/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.7702 - g_loss: 0.7734\n",
      "Epoch 111/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6939 - g_loss: 0.8483\n",
      "Epoch 112/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.6961 - g_loss: 0.8373\n",
      "Epoch 113/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.6352 - g_loss: 0.9398\n",
      "Epoch 114/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.7013 - g_loss: 0.9267\n",
      "Epoch 115/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6883 - g_loss: 0.8689\n",
      "Epoch 116/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6550 - g_loss: 0.9033\n",
      "Epoch 117/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6819 - g_loss: 0.8627\n",
      "Epoch 118/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5229 - g_loss: 1.0656\n",
      "Epoch 119/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.5348 - g_loss: 1.1471\n",
      "Epoch 120/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.4277 - g_loss: 1.2866\n",
      "Epoch 121/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5072 - g_loss: 1.2020\n",
      "Epoch 122/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5588 - g_loss: 1.1327\n",
      "Epoch 123/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5686 - g_loss: 1.0785\n",
      "Epoch 124/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.5295 - g_loss: 1.1782\n",
      "Epoch 125/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5614 - g_loss: 1.1478\n",
      "Epoch 126/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5738 - g_loss: 1.1028\n",
      "Epoch 127/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5365 - g_loss: 1.1413\n",
      "Epoch 128/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6393 - g_loss: 0.9838\n",
      "Epoch 129/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6866 - g_loss: 0.9754\n",
      "Epoch 130/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6901 - g_loss: 1.4688\n",
      "Epoch 131/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.4882 - g_loss: 1.2526\n",
      "Epoch 132/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5917 - g_loss: 1.1324\n",
      "Epoch 133/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6913 - g_loss: 0.9611\n",
      "Epoch 134/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6386 - g_loss: 0.9825\n",
      "Epoch 135/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.6871 - g_loss: 0.9636\n",
      "Epoch 136/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.7026 - g_loss: 1.0742\n",
      "Epoch 137/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.7882 - g_loss: 0.9027\n",
      "Epoch 138/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.6460 - g_loss: 0.9836\n",
      "Epoch 139/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7111 - g_loss: 0.9262\n",
      "Epoch 140/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.4744 - g_loss: 1.4523\n",
      "Epoch 141/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.6716 - g_loss: 1.0026\n",
      "Epoch 142/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5748 - g_loss: 1.0710\n",
      "Epoch 143/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5317 - g_loss: 1.1175\n",
      "Epoch 144/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.5969 - g_loss: 1.0515\n",
      "Epoch 145/150\n",
      "94/94 [==============================] - 4s 47ms/step - d_loss: 0.7618 - g_loss: 0.8295\n",
      "Epoch 146/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.6448 - g_loss: 0.9300\n",
      "Epoch 147/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.5514 - g_loss: 1.0640\n",
      "Epoch 148/150\n",
      "94/94 [==============================] - 4s 48ms/step - d_loss: 0.4546 - g_loss: 1.3600\n",
      "Epoch 149/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.5897 - g_loss: 1.1090\n",
      "Epoch 150/150\n",
      "94/94 [==============================] - 5s 48ms/step - d_loss: 0.4904 - g_loss: 1.2036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fca50035e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKqdR6bOItI4"
   },
   "source": [
    "Display the last generated images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "id": "zZa20XZYItI5",
    "outputId": "e3d85fd7-149b-481f-e5ad-cb1d45787ba7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACPElEQVR4nFWQTU8TURSG3zsfnWk7M8z0SxFqBQrSxIUxVpGYRiW60LBw5YbERP+AKze6MO7YuDbRrYka2Bj/gElDUqhEISYWKBoohdpCoXTaTufjumix493cnPvkec+5h4Sr1MbJYfqGH8tzX3SzW6sKR/5BIf6B/noye4btlJwcz1caAAAiPptWaGO1cfh26N5uEwDhHKHZsYLHT3XvZuodr0cWRrIGgG4k0cy4do5El7y8vdtycuPHOQBcB7K+1Hp1+9p8K+Iv09aOJeYAgOlAq3JWSoThQ63Qf6SEHz6KkJ4JLO7XEdK5Uacy5iHvf5Rpz4Rw37NXL3hG5MGx/mrAWKFwm1LR9jfy3O2NOqVZk2u44ZE4Yd4o+0t/aupaO6CIOccFyeaOmlbMUyp74B0sLvOOa1owKZWKa5W6sV9tGbzEKu5Y8nrxtM2uReVCiRnYtWIFt0luXYyfFyf4SGCSM4WZ2SjprQ8k6MzYdU5IpPPVy8XlGP1JeyZq+rzm93FtnxoqtqVmkHP1pG0crETn+AuFIpMoNcLi4G/aM4FmZmNK4oWbkuS/++plwr0hgPhDbFAK5OXx9qesd4u13CYtX8nXSrXgwHbS2tqo2/+ZIAffNFVfZZNZE6b7nwBgaEPhSelSwHnQfXXDGDH6Wh6jf+qq043qXhTAmzvTVjWsRDJDabdJBADMYdlmtHFbvp45GYJQELBqBUDq4+d1UU8Of33O7XWgx3IIQBwAnhcLrVF1X1n6XqMUAP4CPqvbsJAfOy0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACPklEQVR4nE2Ru3LTQBSGz64kW7J8DZYdy55MYhtjAxMKp2GoGA/MUNHQ0lHQAh2TB6DgGXgGGIYUEDomkExIJmRchBh8jU18Q9iSb9JqKSTZ3m732/8/5z8HYXYGznGZXi6rd6qEWnfEGnPGb06zd6KoevRZ0YECAIIFyz/+ctvF1X7cExIvy20KwM4ZehrINTgzwmaKtPz2yQ4FwHPoT21WWopCD3Ai82n/mg+WoJh7QETkG4BU644mB8HCEmSuPzzcawrjWleLNZlX9FcdLWriJNGw2zUOBxMnvPJ+ZLCYOBDfN8M5v7cfDYreVNF9QcpNlgBmrBjV/L9AU1MnnfPW2OSaJ8Stz20npdfyd349HSJoulZyd9u8agLgAAAAmBPl93ERzrSRD/siV4KJyAwA8MDuyFCrEuiqCjVVaTCVMxMAMJ1PgQ4HXX1Y1ihvFqcEAIAlcyjfNFZDqVwYne9qlgQv5rcmoEFbhb2e22OvgwVkG7uS+Zng6dWPLvqX9h4xYzPGU4CZYrYbwcItcWIrnV0HtzxlxlWayesfxaH9xjquaY6K1GBMvPGce7dtQ4pNAADpUVmJokqMkU53NSc7Zi0ljfeSoltdca38ndJnjq1hQVmT6q2Q2fmpe/v7Lyw3wFYkpA7/IH5KaEhUmS3/mq20/tAbsas8EkNxVQplPrwRGbLc7Wm3r3g6HPWUvNkmHQrqEuTicpTx53TdO/B/ix5ymlVMMHQA4BJ3+fRk41huyV9Xd6aXBqEA8B9Sf/gBq8/nLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB+klEQVR4nF3Sy2sTQRwH8O88Nvtqko222hrbGrCk9eChHgJCBUvRgiDqyaPgH+BNClLQk/+GiHgSRESkeLPtRTwUeiip76RSguZl9pFNdmc8bNLuZo6/D9+Z7+wO4QEGa2Iht3TT9lfC5Y92NOHh0JC/7MztOuXXr9auFT4AAMiRqfs7Mtx47/PiJ2fMTqK1fqtxpi2+GQ+MCp2otmUcCSldeKL8fqk//+vS2altAKBDlFydPwh4YavmMdlwSQKxcK+UUaeXc1lIxepHbYemtKqnCv908fDNO+/qpbLYk7GkcXplWqWsbd4o+nXv2RcST7bDya5NhA7MBmY+SLlxRNdnkgvTxWo5O3d+V8aR64fjOU8InWiL3ub3MFEoPNhyVslMimUc1vjhyOQ9G9t/Hu3XW00ftPsrTCL6X72lUi6d8bLpc7cVJJHY6vUuE4wJdsK0RlDUXlR+BpqWJsTfqY8gJFuvBI4LyrTBNIagM4tGxtBMRbljJL8tQKz7dl/QDiPsbXcUZc1sUZ1RQnrN6K/Q43cC/rSpCwQQQh+cw2I4eUXRFE3lyt1oSseO++QfM864DITCBjisDYJWnocUCHphR4u2cpk4ym6ctQLmGZTSbBsA6LgaRWnOKipTIURK13ByngAA78ior2hqe5uHF6ULI+h+rio9AP8Boce8N9nMFW4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACEklEQVR4nG2RTW8SURSGz50ZKMOUaWdK0pYPtVRsTNWgC6vRRVsSdKGJiTb+BY2JC/+DO03qyqiJcaPxozEloTF2YU0IYqo0JtVYsUCAqQTEwlRghhmG62IGgZa7PM99n3vOuQiMc3E+HnN8P5IaSL3ZkrBeo1rQHB+9YB9jp2wbadGyvQuq/pemp2Pu8srQsnrA9w4AAIgWdASjy0wxIROEl2cCqBsOxCrDXvFT1tM4hIXybDfk41K5vH+GtiXPcNNLVQAAQAY7+hZ/NOXqp5LFjPs9K46/yHQ0pKCHFrJILvQj+IuyBR8g3NYeLszxpXz0a5pLV86VvBWrtUM78TgckKkHB5Xj61eD1nBC+ya1teZFPhKg5wYtCGtqeiXX2S3Krz2xvy79aqgkW6doY0MGxL8j1HyoOZkQRZ67KTehaxQAACb3TPjiXN2sNfFeiNaHr5h3qnGV0HYtHgCwIwwZPGJTqtD1pn648zSnaczof1UnXHulrLIubakk90h+viXxaaffRffSeq4NVSZkcnuwh5byl4hm9bJvI/Vob7L/hnjp2N0/5sXZ1u2OoCAFLazaFKb3sTt6su29Uy+Eaj+LCRz7IOtVylxvBV0IzQhsfLLPzV+/rwAAEKaWuRF9XsuPROyb0u1sUB+GoChDjEJnnSetJ/gp8rTnnr551Kcg44Moxg9ccpz2LHDCD4nAGP4BZl/KH3NsXaMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABlUlEQVR4nG3RSy8DURQH8HPujM5MR9GixDPBorqQIhGRiI3HR7CwtmXDJ7CV2Fj5DrWwsbEgHonYCIKEmMYjRYuOTqfT9t65Nh63cc/y/PI/JycHobpwqGe+qPU33x2sZKgqCuFGfMt0g4Uwfd55ZiAiTgXWozrTiM5Z00ASRMT6+lia6BXFQS1tW1CFMDLWa950kqZLo/zYtY9cRNLX05BrqyldhfZWP0YN4gP5Q/9uINzq0lMttJ72dnO0emxRoU7Buy1tWgDwUL2TpxpC+BrYj2z/dMRkVPXeP88PHSLDs4DSovlmicqQ3WNx7SRfBhnSpDe77aBwnIAQD1oTLfCnKOJybMbKvS3kuSxp9dpmW2yjXTr2+E3LFjrHw1J06qxGcnG7CLJaekndZ63rj0nJKTBnvujoZ9GTjUWlNY+RRFmVJV1uBbmb7qqT3cl8uxyuZPFmWpJk7JIOVp5cTWH/dyqQiOq1w9GjyP+kil6mhnPaHWPfDfX3exCiRcMAt5SKU+IDAKCAmIAOpRHObDvjAwDAFyx1nR/9mU+4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACnUlEQVR4nFWSS0iUYRSGn+/7//n/cWZ0zHQcHR3TyQFRJopulIFdiIICIatFUERtIgiiNrUIatVtVUmLWhQtatOiK0EUFZKhYKZZdlGx22TONE7NpHP552sxWfauDufhvBzec0TTsArE0/q2ZnuHrzGzNWoBgG1j33uHqI+RyDr9VmtLwr70y9OerufKVdn7q0zNCaelZmUrqm1N5uiL5bUP3tzrNnfW7n7fUqYIpxQ3i2cHbuzqWfso9uPZtSPllaZfmI21TmEDdIPskuTJqc3h5szr68MLvLftc8cGhCIDUOOyGXa71li4233Gs2zV1RVBt98xWwIgTtzolDKrBAowd1R5HxqDqfbtwwBics27n6VfVA4As2h95+RUgbfFuvQdkHIqkv5uBxCw+Fzq51h9IJPe26YBcsXHnJVM5gAFdYVBX+Wob2LlyDEFyNWL+Ke7VVfi7vlDpc3ljlUC5MFugZyGp26XTeT6nV/bv3W2GiCF0HW3jgAQfYV1BQlXOH4+ePGzDnpbZcSKgQLA8CX8hub86D07eGt+J7JcWNOuct/VxxFPyfpIQWC4zFwM8uiYpsw/Z3rVEFkUdY8EAtGJ4vsjOgzYQMsPPqkwivz6rMN1hSWnA8GQRB7ygiUAcqGi0oJ5FcGhGvTjciiuoWejTK9TDNy3uRde8mx+VOEqHUV0N6cw0n9jsKsq26QILfCt29iX460GTm1GSrK6yHDdaWr1glxpQtKaAT0tDY79evqmBXJDPf9JhrY0pQY2jWIDkawbm4GEvaQms0bP9fX+sBLwwQl6njwr8VzO7D9xoCM07bJHQjZfl8eMs9b4eJxPADigvYY/b8B4T/9JFQt/+3yhON8RS7vy76NbyvE6+rIhPXVednzNAUL9BtaN71xzKneFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABk0lEQVR4nG2SvUtcQRTFz8z7EA24YNwgQmyWiCQ2SbFgY5t0ASWNiFilS53/IE267YPYJZBABMukSCcBg4IBdbeLRlzwY9e3b8edmTMp3nMzPvc0w9zfnHvn3hmBvkS13Suvbjz6lF7lkTCLP3u81g4+PD+ePps7/J4kLj8OAIgVpQn2uvU5M6r/NhdsBiUA4D1kK8B4jb9PDqJydQqePluSZOeovr3/J03NG3jOmSy5+Flr7Ic2xKrvXKcjL9SP2bj0+td5+3rLhw2SVr2bkkHpwYu3D59IH5Ik9X0BIBp/GgmfQTOTLgkID0kA2Mk3welXCYeCRlRPGdLY680oLEIsL+aZTwN5BwJfMqhGvFj/3Md89Uv2K+zqCHTplR3k/NYDhIgRD4IT97J7vxyUVoeAbTmZevBmHmEnkDy6dKL+6o4znoya5QSqGVcki10OrZC0tqM6ZqzIoLokaRKjWSsyQUOSRlttT4pwmv9lh2/3Gc67fDDOwRWepdLwjKYa3voKlaVuQmt0O0lah9vD8mZs/wCIZNp8jeujQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAClklEQVR4nEWSyWtTYRTFz/fe917Gl7w0NW3Tlzad06bGFpWqUAQtKNSNQzcuWtGVC/EfcCWIIuJeF+pCwYUgCM4joiIOoMUSS0xoarVJ2gzN2De7SE3v9sc5597DJaiPzTr4Q1YAhkqCHNcMAKAUAGOef3Pl2WRZvJxMTLkG13n51gsAYAkALhgtPDK+7E2MSc1pvVy0L8xo5n+ldppN9/7yzy5G+7eqLM1X7jcvA4BGARB/5azVrY0UcSfgHXXLfz5n64tQAMLTwweHM6alpbPWErfKhuXQbR0AwAC4mGbD6Uigt4868i6Hs9bdppOG8tsF+Po5i2zRqVZTOGH2MdUbsO1D16VwwCVwHtHMlUsebVFDw3b8CXdyaiBM+VJV0+1GUd9PNmEkSLSbq1FlOSc6vW38WsewuZm5Ns22H6vZS7xzmXPoJpJ3LVCNDZh76DljkH0KtQpzV0s+MRbTqfFfWbk3ERx/t3txNOWckAVJV2duaI3Mjh5Le7z9VdOCdz6XShayhV1oNMQuT3Ts6KwNGcZPi73KOGnTNRaGWYdm/m8ykyy+3tL5vJJdl8IKfakHljZsmdZHpHREGhdUzS+FdmbexkT8NgGwDGCSnrlyXNZao11HgzybqIWm65EGBRjn8X3xZk6cG7JJBZLyWuev16FJAT39QHnvSI19UfZKMVXLBtQiGvUZiY/bu09sa2864K8qNtZmFX2bp6AvJOxZ9C21fA1Fia7yPsOdAQAQCuDxKZcgJR1fg5VIwi1zGd9vYjaUk5HCt9QaQ/OugiVbXPHzcp0xFEBhjWNGvvcYvrLoVmIRqoR/1B+dACTuEhc8eUZlFVXPpXVSXTkHAPASAMLukI0ZoDJv0zzR2ZK2+kmub/sPioYTICIeP1sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACrElEQVR4nCXBzWtcVRgH4N977rkzmU4m/Uhj0+iEaJpiKigEF64UKi5UENy5EqU7/4DizpV0I7oRFRfulLpREQSlK1ERbYINxjbTaNKZpJmZziRj5uZ+nHvO+74ufB76ZnWj9tvRwtKj0v6ly6CIghHB/1J3e/v6m9e73ey4/0bz/PO/tge7pbtxEgBQslsfXMuyUISs9c79nTJjFhH3PgFU2iHv1Zsnjsid/e7E07ENXCcC/JXP1Simw9J8nRqVM3hmtupNVGUAsM0LMEB5/2MK0k5HvDZhJ3Pf47EC9O5HxhIqU2/FVuYD5ImJqIztbDoFALgpxmE0uHJ709/Jh9zrJ84Vd7tpYAAfgrIJeRCqp4nFeBemQYoiNhGRfv+y8cjvvdft825+iOOdfXIq8d7etigMUVrTrMYgsJYTZfuhhvVJI7JE2Hrc5Fqi5Y+17/ddUrl4GvzAjfJtBV4AchEfvHDwRZIUwZeZS8eZF+G3yYYqh6QhVgmyE289GRrJuR7F80S3QD5SVwWL5XF/Li/sjArFFBHw83Pk4lw6C91T/yxurHybJa+EubwhVa4izB7CC/skL9OdkZPhJ1tpkuXOi4iUnxljANNL/tz/UtYGX6wwb40PRQHArisJACgJSKU1WK5ZVCgCAHQeMwqgCA4M1R/PdbST5CwApHgdJABUjULzzbMPm3BsqtYSkJedFQMA/wrrveSviwdulLQO7owBALV9IQEUbEWVnbHiOY6tBXAU4ZRVGpVXLy8+NXxkt37QzGx7AW4y8sWyS8UwKrvNPy7obDpj582kmfYZeU3Xe6MSJsfvNz746bXiU2lld8ed3urRrZ6Xza8AwBhc+mE5frX+ol0wM2EKi9GlOcLMKgDQzTMv/S1kLg+fdUu6xLWN8/XJtYOvXQfAf2Avn1B7WqAKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACAElEQVR4nF3QS08TURTA8XPv7XQenUdnAAuWEgTBoJFEJRrckBiXrly58Au48gv4EdwaY1yy9wOwYaEbTAwhEZtg04qpnZa2dNp5v+51oaWdnu0v/3NuLsBksFj5cNCrvtkpYJgd9XUtpowmbfN4/5ZAponsfTMH9sjvm61RFMUfn/MIcv9NuP9OTHzGewER/EBgL6zDhI1x4y0xwZFK59dD6VRpl+YeEkTHuMT+5GPL00rNRCmipYDEIb0qH9VLQS+sFS7U6npI+k2vy9HxTcx4RxDQL3dxKCPbqNVPzxMYIxuJ22Hy40S//exI9bpH3x0GVwjcDblQ7T9NWu8Np1yLYoAJss/8K1bo5D4V3DuuH9HlRgoAaPJ5OUwCEOaLC1p41h1MlQBAI4S5BFgOznodClkEYBQIs9jQGI6XTf8vi9OUcWsu/y+cKhFg0GgxKY9W2ohlS/SEx3OGmq7qW9s7MFNuDlKpYvNlSfWMcPbmrpzXFxck7jIvNgyWLfFLfv+E13UJ21itY5otZXy3+OCe3OGEkrCKs2VOs24+LlvMh7i715tZqwSmvoaqcVpEekOj2QctqxXOd+XY9Uln8EXMINq4uOylxOLFLbTrbM5nEA+qoyBsKFRvXWPrx3HmZtr8quRt6Sfy0rpmOt0Mos7vCrW1lYSLfMX2SQIAAH8BH2ricWt9GlUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB+klEQVR4nGWST2sTQRjGn5nZ/93ubtdaNaaGtgdDEw1oLoJYBBV7qEpvInrxZj+JX6AXD548iODJg4oIYsAaJEEhoEiCwWJqNbZm0xiTTMbD7nYHnMvMO79533mfZwZIxsXuym0qxZCDFy+LV3mGJBuKBJcX1m4Mitt/kh3p4GZ95b6ikINRqDKFiH3o32GV7JGfzsZfAMAQVE9u6H1rvrl7xc4SEpUkUuZqWi21Wux6qcGNPgDASu5k+iHV0s4+PKGZKgFAqNQuHzo31Uk3u80NLgAI6ktahHe5en75CVP4OFSiDRKoV6qvHy/MPuVc7QIAdWW7vPe12YmqM54PG6YjCQ7eKc2C6rgHdnriv7JmmubN1MdGLZJHJeft/r2loPJMmzoWvYeSauzDLi6MVDPP8l8RptJ2jAgoOLifJv5ODAuxsyAmEUD/kzgaN6m8jRaZyQ9Gjwj1pMcbPJYWV83dWsproGTGbdOJGEb2sS9N22dgjtiwXsWW0h/hPDae/+4MhdD3cgNmUECVdBI+U8xlPH3xe+2SsSuAIQAam7F1bnWocxbM2fWga51iAECnInfMyqPNgpZ6sH560c7SugkAym4IA/MzbfIeL4+mS3Nl49cYAKgIv4LF+TVvgE67fHxtOnc4asQLU3WqOZ0+2JmW6wVbe71gDOAfR6WkK4E55N0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABxElEQVR4nF3Qz2sTQRwF8Ped2R9NNrpxi4m11GDR9tKeqgUPgiDYe26CN/8B8V/oWU/eBPUuFHryoIjngsX6GxW1RQVbupra3U2y2XkekmaTneN8ePN4IxgcpasPa1sPPqapCS5zjQAgfVp5AmSaydvu7qv64odbHQCABQBqLwCoIanXKs/W3ChFjjcCAEKgcmo1tptu2wyqAODRUTEqK+cubJ3WTo7bQ4vM66l1c38zyzE9MobJtcDd2PmVP2vNDtE98Panbla7GGLZAAAJdrejf993N363cowGW5nR85MZ/+L0tAwx2wRJgOI07KWludrVTp7Eer8/o2jtfa56Zm9k593HfE8yzcgDaQefPGckGV/XCy/Jlq30M0v/WDgzj5HvA3Dp0J5U0M5E893xOgvo2MoGdNXamZvEfgETgYDqZE/xeaMx0tlfiS4EoZVOLC82C0kQGoDP5XYm5WJSQQNyXv2xTygpYn+3j1jicEbGUQQZACXsSKXEcXSJBCBZc4xdKiR9YQiIo1LjybdCZ+/pl1UCAlelat4Zn/L3xb03BA0QlWzTG8cr0jiriJ4oK6qEhU/4ebv+NYM5NHF4LL0zuPwPXhKvcn/+o6IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACB0lEQVR4nG2STWsTQRjHn2ff8uJmdd2mNTVoi4IWRc1dkHoQjz0IfgHFbyB4FDz5BQRvvRQEQbzUk96EWmiR+hbRS9U2qekmJtndzGTmmfEQk+4Wn8MMzI//83/+M4MwLrSXvMYqaPhfWY19IdSfQbS3ND4yJvA+IjeV+9b5es8+dxj6UbEAprFIlZnX67ecLPy0pwgUgB28e5pfWa4BgDWBdSJyEUB9bzXJuR3cSCs/b6ytcgIebQYX10NYzKUgnor1BUXU61evHdt/1Tgvxm0Njd6drfLzu/Lsm8Ja85FSo3SjlQpWqVqaTXrlLf2rJjM5SaPf0haTJ2Cz7wcTKwAAWCg9fH89njEqTNST3UtX/93hqO0zmMvzjTOsG58u58O+zih54nXyO66RE64wtytB2hM/SLDsfC62Y2raJ4uYUqLJEbg1tBgmR8iVVtA9UGqJoCzT1GESiYj3cWr8iqONtf2CgSXXLtiWjWYmZ9Gdj1RCTHZEU0ldwzRkynjMQ61Nz5k2C/pKRgkgWNhTOm6pthrorp3xBKPOmDxaROu46aAPgDqlpIXIMGIZUVuCvuxlPiH++Bh1RV8mMpFDGqxM5VLw5pDJzjAhRgORyEF3eRYP4AsSlEhOjIaSE+e7X4wDT08iaa0UaKVBK+n6c5Np8cFL0/lZ/T29UwkrPe9b6cn8NgD8BcEX/AFyWbkcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABpUlEQVR4nG3SO0/CUBQH8HPbeym1FCz1SUQTGYzRQTYHB+PgpF/MxDg6O/gJ/ADGGBc1aiBGBCVNAMF3FemDtvc6aGkL3Kk9v5z+zz0pgtBBRBUXcvTAYNB/kLRxVGoyzTvejP9Xesbv2ev51275xp4TxjcdAAAcdBpafj91B41MYf2Q9CGy1jTXXm0sSedaIWUAAHA95Oi11py+Txtf1Bj9Sws64yK4RrnTRfWmmQbEIvgzaqqgfMffmreTlxYHXiRTfrVl873oXDVKFqPRTMWzs5KizDqO7ngUIsivvEx3+PZYG2HW9WfsDeuKTH2eEjKJ8eAC/gPZqC1lc8mMNE/JAIq7lROEJ6vu45jVmzFYH2R3HmK1ll6rOv2dAPCBr4XPmJeI+YXQ4gG+TpNFYgfvYbQcNafP6Am7MgRZantrZIKZLz6GMzF/9lZHF4lVNATR06O3+B2Tk8OQegougc5a/v8VzuTa4k0dkXYOO4OIZDcdl4qpMhmC+OOzI1f5q4q/oQiWrcJDsipy1P9UCCVVXwZaJ6alD0zLCUTBXU/gO+J/5ReAWKjUtENyOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "for i in range(1,15):\n",
    "  display(Image(\"generated_img_0_\"+str(i)+\"9.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 45
    },
    "id": "aGPzZXYZHY7Z",
    "outputId": "97bab913-4d01-42dd-a210-d03c98ec909e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAACV0lEQVR4nFXQS2sTURQH8P+dO5N5JJm8mjZOjUlLbWmgxWrqQlBBaF2IG5eCiy78BOLaDyCCCwU3YkG6cFcEFdGd4EYEqVraUrWVVJtpXm0yk8k87nXRpI13eX78zzn3EBw/MZK72HRq3+pOt0COSLhSvHFas6nVePryr8X6MBQU717/3EoN/9laOUdSujG5e4yLo9NEbLGm6lTCeptnxPXZIzy15dO1bNXcMM/uFjaN+tTybY0BAgBgCSIZgRRCIRrZDnuGeFUIAxABAAbhAWEcBX1Ab1jpQFeJ38Ps9ghnLce0l0/qMsmvDq+qkoNu2+pjzuqukyy/fjU+N2TmyvK9ZKSX7IyCiMTcobes9eXEoBzaNxZ4LxnECFE1KVbLbvzaSkXE+tCdiaCH5H7D6ZTsduLtTxRVZU/ftHx2fITvB2uXT+yX957F5xJew/IWhfxz3v0KpqXwJ5FKihGr8476cTI/cP5Fp4dB4BI4dDBDeS5W4kv6u4dHRwBAdT/E/JnYfqXNJ978NtFbCJiHsMGcUk1iYiI2fimooA9XkDnzg/g05Fqe3WzUGe9DE1FxTIuoLqsmNKUTOyx3Z3LypF0ruy5jqZZLSj75H63381SmHdtMOpEvMu+fiXR+LICsxKnKbFzzCelLKhfKcbm5I6mBR7KeoZL+haZmsrXyQTKXoIJTdaWM1NeWPJh0Q9aATWxpT4qnEjejhygAgCrNqEbUVwOPGirh2mxBBgCRMgBijjbTUprQeFvWqK8M5T4AgCgQDsV/lCs28NWrtxQvoumd1Wq8AuAfxjfv/sJadXgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 10\n",
    "display(Image(\"generated_img_0_\"+str(i)+\"8.png\"))\n",
    "#display(Image(\"generated_img_1_'+str(i)+'8.png\"))\n",
    "#display(Image(\"generated_img_2_'+str(i)+'8.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idate_fObUtI"
   },
   "outputs": [],
   "source": [
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=3, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-o1cIfLhXhq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "gan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
