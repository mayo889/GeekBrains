{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практическая работа к уроку №6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import (roc_auc_score, precision_recall_curve)\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. взять любой набор данных для бинарной классификации (можно скачать один из модельных с https://archive.ics.uci.edu/ml/datasets.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection\n",
    "\n",
    "YouTube Spam Collection Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = [\n",
    "    \"YouTube-Spam-Collection-v1/Youtube01-Psy.csv\",\n",
    "    \"YouTube-Spam-Collection-v1/Youtube02-KatyPerry.csv\",\n",
    "    \"YouTube-Spam-Collection-v1/Youtube03-LMFAO.csv\",\n",
    "    \"YouTube-Spam-Collection-v1/Youtube04-Eminem.csv\",\n",
    "    \"YouTube-Spam-Collection-v1/Youtube05-Shakira.csv\"\n",
    "]\n",
    "\n",
    "df = pd.concat([pd.read_csv(path_df) for path_df in datasets_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. сделать feature engineering\n",
    "3. обучить любой классификатор (какой вам нравится)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment_id</th>\n",
       "      <th>Author</th>\n",
       "      <th>Date</th>\n",
       "      <th>Content</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^ ﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .﻿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Comment_id            Author  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  Date                                            Content  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43   me shaking my sexy ass on my channel enjoy ^_^ ﻿   \n",
       "4  2013-11-10T16:05:38            watch?v=vtaRGgvGtWQ   Check this out .﻿   \n",
       "\n",
       "   Class  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [column.capitalize() for column in df.columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#соберем наш простой pipeline, но нам понадобится написать класс для выбора нужного поля\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.column]\n",
    "\n",
    "classifier = Pipeline([('content_selector', FeatureSelector(column='Content')), \n",
    "                     ('content_text_tfidf', TfidfVectorizer(sublinear_tf=True,\n",
    "                                                            strip_accents='unicode',\n",
    "                                                            analyzer='word',\n",
    "                                                            token_pattern=r'\\w{1,}',\n",
    "                                                            stop_words='english',\n",
    "                                                            ngram_range=(1, 1),\n",
    "                                                            max_features=10000)), \n",
    "                     ('classifier', RandomForestClassifier(random_state = 42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_pred)\n",
    "\n",
    "    fscore = (2 * precision * recall) / (precision + recall)\n",
    "    ix = np.argmax(fscore)\n",
    "    \n",
    "    return fscore[ix], precision[ix], recall[ix], roc_auc_score(y_true, y_pred), thresholds[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим данные на train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Class', 1), \n",
    "                                                    df['Class'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#обучим пайплайн на всем тренировочном датасете\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['RandomForest'] = get_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. далее разделить ваш набор данных на два множества: P (positives) и U (unlabeled). Причем брать нужно не все положительные (класс 1) примеры, а только лишь часть\n",
    "#### 5. применить random negative sampling для построения классификатора в новых условиях\n",
    "#### 6. сравнить качество с решением из пункта 4 (построить отчет - таблицу метрик)\n",
    "#### 7. поэкспериментировать с долей P на шаге 5 (как будет меняться качество модели при уменьшении/увеличении размера P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# доли P\n",
    "sizes_P = np.arange(0.2, 1.01, 0.05)\n",
    "\n",
    "for size_P in sizes_P:\n",
    "    mod_data = df.copy()\n",
    "    \n",
    "#     Извлечем size_P долю объектов с таргетом 1 из датасета\n",
    "    pos_ind = np.where(mod_data.loc[:,'Class'].values == 1)[0]\n",
    "    pos_sample = np.random.choice(pos_ind, replace=True, size=int(size_P * len(pos_ind)))\n",
    "    \n",
    "#     Заведем новый столбец с фейковым классом\n",
    "    mod_data['fake_class'] = 0\n",
    "    mod_data.iloc[pos_sample, -1] = 1\n",
    "    \n",
    "#     Извлечем из датасета множество P.\n",
    "#     Из множества U извлечем множество N такого же размера как и P\n",
    "#     оставшиеся объекты останутся для валидации\n",
    "    mod_data = mod_data.sample(frac=1)\n",
    "    condition_true = (mod_data['fake_class'] == 1)\n",
    "    condition_false = (mod_data['fake_class'] == 0)\n",
    "    size_data_P = sum(mod_data['fake_class'] == 1)\n",
    "\n",
    "    data_N = mod_data[condition_false][:size_data_P]\n",
    "    data_U = mod_data[condition_false][size_data_P:]\n",
    "    data_P = mod_data[condition_true]\n",
    "    if data_N.shape != data_P.shape:\n",
    "        print('error')\n",
    "    train_data = pd.concat([data_N, data_P]).sample(frac=1)\n",
    "    \n",
    "#     Обучение модели\n",
    "    classifier.fit(train_data.iloc[:,:-2],\n",
    "                   train_data.iloc[:,-1])\n",
    "#     Предикт на множестве U\n",
    "    y_pred = classifier.predict_proba(data_U.iloc[:,:-2])[:, 1]\n",
    "    results[round(size_P, 2)] = get_metrics(data_U.iloc[:,-2], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fscore</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.85</th>\n",
       "      <td>0.925</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.920</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.55</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.929</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.65</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.892</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fscore  precision  recall  roc_auc_score  threshold\n",
       "RandomForest   0.952      0.969   0.935          0.977      0.480\n",
       "1.0            0.937      0.939   0.935          0.983      0.442\n",
       "0.9            0.936      0.971   0.904          0.978      0.445\n",
       "0.85           0.925      0.974   0.881          0.973      0.477\n",
       "0.75           0.920      0.926   0.914          0.978      0.380\n",
       "0.55           0.919      0.936   0.902          0.976      0.360\n",
       "0.95           0.919      0.941   0.897          0.979      0.420\n",
       "0.6            0.918      0.910   0.926          0.981      0.385\n",
       "0.5            0.912      0.911   0.913          0.968      0.375\n",
       "0.7            0.910      0.894   0.926          0.975      0.340\n",
       "0.35           0.906      0.929   0.884          0.974      0.412\n",
       "0.4            0.902      0.900   0.904          0.966      0.348\n",
       "0.8            0.899      0.968   0.839          0.968      0.485\n",
       "0.65           0.897      0.944   0.855          0.970      0.450\n",
       "0.45           0.897      0.899   0.895          0.966      0.310\n",
       "0.3            0.892      0.870   0.915          0.960      0.298\n",
       "0.25           0.876      0.859   0.895          0.950      0.315\n",
       "0.2            0.862      0.872   0.853          0.934      0.340"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame.from_dict(results, orient=\"index\",\n",
    "                       columns=['fscore', 'precision',\n",
    "                                'recall', 'roc_auc_score', 'threshold'])\n",
    "result_df = result_df.sort_values(by='fscore', ascending=False).round(3)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты получились вполне логичными. Чем меньшую долю P мы отбираем из датасета, тем меньшее качество модели мы получаем"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
